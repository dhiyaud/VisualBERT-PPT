{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333520b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3c7d95",
   "metadata": {},
   "source": [
    "Note:<br>\n",
    "This demo is adapted from the LXMERT Demo present here: https://github.com/huggingface/transformers/tree/main/examples/research_projects/lxmert\n",
    "<br>and VisualBERT VQA Demo present here: https://github.com/huggingface/transformers/tree/main/examples/research_projects/visual_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aa65fa",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d978e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import io\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7498569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Config\n",
    "from IPython.display import Image, display\n",
    "from processing_image import Preprocess\n",
    "from visualizing_image import SingleImageViz\n",
    "from modeling_frcnn import GeneralizedRCNN\n",
    "\n",
    "from evaluate import load\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorWithPadding,\n",
    "    PreTrainedTokenizerFast,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    VisualBertForPreTraining,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c974b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0 ; cuda: cu117\n",
      "torch: 1.13\n"
     ]
    }
   ],
   "source": [
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device, \"; cuda:\", CUDA_VERSION)\n",
    "print(\"torch:\", TORCH_VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43be343",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50e5946b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration file cache\n",
      "loading weights file https://cdn.huggingface.co/unc-nlp/frcnn-vg-finetuned/pytorch_model.bin from cache at /home/dhiya/.cache/torch/transformers/57f6df6abe353be2773f2700159c65615babf39ab5b48114d2b49267672ae10f.77b59256a4cf8343ae0f923246a81489fc8d82f98d082edc2d2037c977c0d9d0\n",
      "All model checkpoint weights were used when initializing GeneralizedRCNN.\n",
      "\n",
      "All the weights of GeneralizedRCNN were initialized from the model checkpoint at unc-nlp/frcnn-vg-finetuned.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GeneralizedRCNN for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# load models and model components\n",
    "frcnn_cfg = Config.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\")\n",
    "frcnn = GeneralizedRCNN.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\", config=frcnn_cfg)\n",
    "\n",
    "image_preprocess = Preprocess(frcnn_cfg)\n",
    "\n",
    "visualbert_pre = VisualBertForPreTraining.from_pretrained(\"uclanlp/visualbert-vqa-coco-pre\")\n",
    "\n",
    "bleu = load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3d49208",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=\"model/tokenizer.json\",\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\",\n",
    ")\n",
    "\n",
    "model_text = AutoModelForSeq2SeqLM.from_pretrained(\"model/stone-seq2seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d20dd578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visualizing frcnn output\n",
    "def showarray(a, fmt=\"jpeg\"):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = io.BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5aef590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run frcnn\n",
    "def run_frcnn(URL):\n",
    "    images, sizes, scales_yx = image_preprocess(URL)\n",
    "    output_dict = frcnn(\n",
    "        images,\n",
    "        sizes,\n",
    "        scales_yx=scales_yx,\n",
    "        padding=\"max_detections\",\n",
    "        max_detections=frcnn_cfg.max_detections,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d52615cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique word from text\n",
    "def format_unique_word(text):\n",
    "    words = text.split()\n",
    "    return \" \".join(sorted(set(words), key=words.index))\n",
    "\n",
    "# formatting caption\n",
    "def formating_text(captions):\n",
    "    flat_text = \" \".join(captions)\n",
    "    return format_unique_word(flat_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c9eaf9",
   "metadata": {},
   "source": [
    "## Load captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6917840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>Singkapan batuan sedimen klastik dengan bidang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>Singkapan batuan sedimen klastik dengan bidang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>Singkapan batuan sedimen klastik dan batulumpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>batulumpur karbonatan dan Singkapan batuan sed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>Singkapan batuan sedimen klastik dengan bidang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>Pecahan koral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>Pecahan koral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>Pecahan koral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>Pecahan koral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>Pecahan koral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image                                            caption\n",
       "0  1.jpg  Singkapan batuan sedimen klastik dengan bidang...\n",
       "1  1.jpg  Singkapan batuan sedimen klastik dengan bidang...\n",
       "2  1.jpg  Singkapan batuan sedimen klastik dan batulumpu...\n",
       "3  1.jpg  batulumpur karbonatan dan Singkapan batuan sed...\n",
       "4  1.jpg  Singkapan batuan sedimen klastik dengan bidang...\n",
       "5  2.jpg                                      Pecahan koral\n",
       "6  2.jpg                                      Pecahan koral\n",
       "7  2.jpg                                      Pecahan koral\n",
       "8  2.jpg                                      Pecahan koral\n",
       "9  2.jpg                                      Pecahan koral"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions = pd.read_csv('dataset/caption.txt', sep=';')\n",
    "\n",
    "print(captions.shape[0])\n",
    "captions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6776aaf",
   "metadata": {},
   "source": [
    "<b>-- Skip line below if you have the metadata images files --\n",
    "<br>Line below for generate metadata image files</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe5fab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_group = captions.groupby('image').agg(', '.join)\n",
    "\n",
    "metadata_item = []\n",
    "for index, row in caption_group.iterrows():\n",
    "    obj = {\"file_name\": row.name, \"text\": row.caption}\n",
    "    metadata_item.append(obj)\n",
    "\n",
    "metadata_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metadata.jsonl\", 'w') as f:\n",
    "    for item in metadata_item:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eeffcb",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d32867",
   "metadata": {},
   "source": [
    "<b>-- Skip line below if you have the trained model files --\n",
    "<br>Line below for training the VisualBERT model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f785f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524924c3ed154aa7a710ee1568196d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faad4a20cfdd4f58aad8c47b7d155b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b042578067b5d1d0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to /home/dhiya/.cache/huggingface/datasets/imagefolder/default-b042578067b5d1d0/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n",
      "                "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b18e2091a642bc969e5326448990de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #0:   0%|          | 0/8 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f48a81b77204ab0a0047600b56f67a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #8:   0%|          | 0/7 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1055a083586342c784d1ff078a3ebf64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #9:   0%|          | 0/7 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8ff8ae9d12473e9b676b1b2f3bc18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #13:   0%|          | 0/7 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4dde0e50092439aae70bca22ee1df74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #7:   0%|          | 0/7 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a35ce7c7394ead9f15a75061c6f41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #6:   0%|          | 0/7 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab9d20b426b42519fc958ae819123a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #4:   0%|          | 0/7 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54bba23cc66b4b348ce1ab672aafea3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #1:   0%|          | 0/7 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b653b9f8a94333a9d8477c1b3fa1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #14:   0%|          | 0/7 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8f8df600a446aba6c35301fa6cbe0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #5:   0%|          | 0/7 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbada497f617499daf4d7eb103a1aac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #15:   0%|          | 0/7 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1b69b6c9fd44358e1b817ad1b93221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #3:   0%|          | 0/7 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782a051aea974c15958575e04e425b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #10:   0%|          | 0/7 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23431f506d1432d823b4a6afa6cd6df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #11:   0%|          | 0/7 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8d09c73b79436dbdc7da26542bafe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #12:   0%|          | 0/7 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba6a00665e5452bb7c21ff3a791ef3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #2:   0%|          | 0/7 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8092e5e6fe6c46488263ed964b255cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299600babab646f6b6b81a1a8c991398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbe06f0ece6499cb4696adeca375205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #12:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc374ffda4b49c3869c4e906d90d302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #8:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35db94180f74cc1bd42de9437e32caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #14:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7806409a2c4becbad149679adaa9ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #1:   0%|          | 0/2 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6ddab2cfc2401682abede7c87ac73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #5:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3bf5e337abd4fe4879c31d26e94f963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #0:   0%|          | 0/2 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc94011411914140bd9d5c5dbc814349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #6:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d2de30dcd945b9abad4bce90aa9859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #11:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc90e6caba94b098787dd11ab7f5190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #13:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d4e75f93114519893ef40504afaf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #7:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5672ac7fd349718563b36125def6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #4:   0%|          | 0/2 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8d3bf151064298ada9d56caaaf9bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #2:   0%|          | 0/2 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20811b68a8d4d25a36ff7b335fe7cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #10:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657e27b723af46f19cf60ea9260e2f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #3:   0%|          | 0/2 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b31fdf5812406a82d675bd3ec7a9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #15:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a21f36dd9034e3bb19fe602b27894d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #9:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e5661efe314c5ead3cbca690179b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e14dfec6844c05a583779abf432219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/112 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imagefolder downloaded and prepared to /home/dhiya/.cache/huggingface/datasets/imagefolder/default-b042578067b5d1d0/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23cc6fcc27334e4997e7f4680f532761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"imagefolder\",\n",
    "    data_files={\"train\": \"dataset/mini_data/train/**\", \"test\": \"dataset/mini_data/test/**\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a9ae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    text_caption = format_unique_word(examples[\"text\"])\n",
    "\n",
    "    output_dict = run_frcnn(examples[\"image\"])\n",
    "    features = output_dict.get(\"roi_features\")\n",
    "    \n",
    "    inputs = wrapped_tokenizer(\n",
    "        text_caption,\n",
    "        padding=\"max_length\",\n",
    "        max_length=20,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=True,\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "    )\n",
    "\n",
    "    visual_embeds = features.squeeze(0).squeeze(0)\n",
    "    visual_attention_mask = torch.ones(features.shape[:-1]).squeeze(0)\n",
    "    \n",
    "    inputs.update(\n",
    "        {\n",
    "            \"visual_embeds\": visual_embeds,\n",
    "            \"visual_attention_mask\": visual_attention_mask,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    max_length = len(inputs[\"input_ids\"]) + features.shape[-2]\n",
    "    labels = wrapped_tokenizer(\n",
    "        text_caption, padding=\"max_length\", max_length=max_length\n",
    "    )[\"input_ids\"]\n",
    "    sentence_image_labels = torch.tensor(1).unsqueeze(0)  # Batch_size\n",
    "    \n",
    "    feats_info = {\"labels\":labels, \"sentence_image_labels\":sentence_image_labels}\n",
    "    inputs.update(feats_info)\n",
    "    return inputs\n",
    "\n",
    "datasets_encoded_train = dataset[\"train\"].map(preprocess_function)\n",
    "datasets_encoded_test = dataset[\"test\"].map(preprocess_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5877735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "#     if data_args.ignore_pad_token_for_loss:\n",
    "#         # Replace -100 in the labels as we can't decode them.\n",
    "#         labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f36479",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./trainer/results\",\n",
    "    logging_dir=\"./trainer/logs\",\n",
    "    num_train_epochs=100,\n",
    "    logging_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=wrapped_tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=visualbert_pre,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets_encoded_train,\n",
    "    eval_dataset=datasets_encoded_test,\n",
    "    tokenizer=wrapped_tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde7fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab37c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba4db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = trainer.predict(datasets_encoded_test)\n",
    "len(predicts.predictions[0])\n",
    "\n",
    "test_predictions = predicts.predictions[0].argmax(-1)\n",
    "\n",
    "for i, item in enumerate(test_predictions):\n",
    "    print(f\"\\nPrediction {i+1}:\\n {wrapped_tokenizer.decode(item)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d7e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"model/stone-visualbert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96157dc5",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc50ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = VisualBertForPreTraining.from_pretrained(\"model/stone-visualbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73f9f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_visualbert_model(image_feature, caption):\n",
    "    inputs = wrapped_tokenizer(\n",
    "        caption,\n",
    "        padding=\"max_length\",\n",
    "        max_length=20,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=True,\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    inputs.update(\n",
    "        {\n",
    "            \"visual_embeds\": image_feature,\n",
    "            \"visual_attention_mask\": torch.ones(image_feature.shape[:-1]),\n",
    "            \"output_attentions\": False,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    max_length = inputs[\"input_ids\"].shape[-1] + image_feature.shape[-2]\n",
    "    labels = wrapped_tokenizer(\n",
    "        caption, return_tensors=\"pt\", padding=\"max_length\", max_length=max_length\n",
    "    )[\"input_ids\"]\n",
    "    sentence_image_labels = torch.tensor(1).unsqueeze(0)  # Batch_size\n",
    "\n",
    "    outputs = trained_model(\n",
    "        **inputs,\n",
    "        labels=labels,\n",
    "        sentence_image_labels=sentence_image_labels,\n",
    "    )\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d091baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_search(text):\n",
    "    input_ids = wrapped_tokenizer.encode(text, return_tensors='pt')\n",
    "\n",
    "    # generate text until the output length (which includes the context length) reaches 20\n",
    "    greedy_output = model_text.generate(input_ids, max_length=20)\n",
    "    \n",
    "    output = wrapped_tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d78efde",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_path = 'dataset/Flickr8K_Text/Flickr_8k.testImages.txt'\n",
    "\n",
    "my_file = open(data_test_path, \"r\")\n",
    "data = my_file.read()\n",
    "test_list = data.split(\"\\n\")\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895d1c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_avg = 0.0\n",
    "\n",
    "for file_name in test_list:\n",
    "    print(\"File : \", file_name)\n",
    "\n",
    "    image_caption = captions.loc[captions[\"image\"] == file_name][\"caption\"]\n",
    "    list_image_caption = [''.join(col).strip() for col in image_caption]\n",
    "    formatted_image_caption = formating_text(list_image_caption)\n",
    "\n",
    "    file_image_path = f'dataset/Flicker8k_Dataset/{file_name}'\n",
    "\n",
    "    img = PIL.Image.open(file_image_path)\n",
    "\n",
    "    output_dict = run_frcnn(img)\n",
    "    image_feature = output_dict.get(\"roi_features\")\n",
    "    \n",
    "    outputs_model = test_visualbert_model(image_feature, formatted_image_caption)\n",
    "\n",
    "    prediction_logits = outputs_model.prediction_logits.argmax(-1)\n",
    "    predict_caption = wrapped_tokenizer.decode(prediction_logits[0], skip_special_tokens=True)\n",
    "    predict_caption_greedy = greedy_search(predict_caption)\n",
    "    \n",
    "    predictions = [predict_caption_greedy]\n",
    "    references = [[[caption] for caption in list_image_caption]]\n",
    "    bleu_result = bleu.compute(predictions=predictions, references=references)\n",
    "    bleu_avg = bleu_avg + bleu_result[\"bleu\"]\n",
    "\n",
    "    display(img)\n",
    "\n",
    "    print(\"Caption:\")\n",
    "    for i in range(len(list_image_caption)):\n",
    "        print(f\"{i+1}. {list_image_caption[i]}\")\n",
    "\n",
    "    print(\"\\nFormatted caption:\\n\", formatted_image_caption)\n",
    "\n",
    "    print(f\"\\nPrediction:\\n {predict_caption}\")\n",
    "    \n",
    "    print(f\"\\nGreedy search:\\n {predict_caption_greedy}\\n\")\n",
    "    \n",
    "    print(f\"BLEU Score:\\n {bleu_result}\\n\")\n",
    "    print(100 * '-' + \"\\n\")\n",
    "\n",
    "print(f\"Avg. BLEU Score: {bleu_avg / len(test_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395b1b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
